{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009f5006",
   "metadata": {},
   "source": [
    "# Tutorial 4 - Objective magnification\n",
    "\n",
    "Welcome to the fourth tutorial of this series!\n",
    "In this notebook, we'll investigate the effect of the objective magnification on the structure function.\n",
    "This allows us to extend the range of wave vectors that can be analyzed with DDM to lower values.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "The goal of this tutorial is to demonstrate the effect of the objective magnification on the results obtained by DDM.\n",
    "Specifically, we will:\n",
    "\n",
    "0. Set up the workspace and import the libraries\n",
    "    1. Set up the workspace.\n",
    "    2. Give an overview of the sample under investigation.\n",
    "    3. Import libraries.\n",
    "1. Compute the structure function of image sequences using DDM.\n",
    "    1. Load the image sequences and see the effect of different objective magnifications on the input images.\n",
    "    2. Calculate the corresponding structure functions.\n",
    "    3. Calculate the azimuthal averages.\n",
    "2. Fit the azimuthal average to gain insights into the sample's dynamics.\n",
    "    1. Estimate the parameters.\n",
    "    2. Fit the data using a diffusive dynamics model.\n",
    "    3. Observe the effect of the objective magnification on the limits of the technique.\n",
    "    4. Fit the parameters obtained from the fit to the data to retrieve the diffusion coefficient of the particles.\n",
    "\n",
    "This tutorial assumes that you have a basic understanding of the features offered by fastDDM. If you need a refresher, consider reviewing the [\"zeroth\" tutorial](../Tutorial_0-Introduction/tutorial0.ipynb).\n",
    "It also builds on top of the previous tutorials [1](../Tutorial_1-Particle_sizing/tutorial1.ipynb) and [2](../Tutorial_2-Melt/tutorial2.ipynb).\n",
    "\n",
    "At the end of the notebook, there will be an optional (starred) section:\n",
    "\n",
    "* (*): Figures for the objective magnification section of the paper.\n",
    "\n",
    "## 0. Initial setup\n",
    "\n",
    "### 0.A. Setting up your workspace\n",
    "\n",
    "Before we dive into the analysis, make sure you have **fastDDM** and the required scientific analysis, fitting, and visualization packages installed on your machine. Refer to the main [README](../README.md) for installation instructions.\n",
    "\n",
    "For this tutorial, we'll be using custom microscopy videos acquired for these tutorials.\n",
    "If you haven't done so already, download the files (the `DATASET` folder) in the directory containing these tutorials.\n",
    "\n",
    "Your main directory tree should resemble the following:\n",
    "```\n",
    ".\n",
    "├── DATASET\n",
    "│   └── ...\n",
    "├── Tutorial_4-Objective_magnification\n",
    "└── ...\n",
    "```\n",
    "\n",
    "### 0.B. Sample description and experimental parameters\n",
    "\n",
    "The sample under study consists of a dilute solution of polystyrene spheres (PS, nominal diameter 252 nm, Microparticles GmbH) dispersed in a glycerol aqueous solution ($c_{\\text{gly}} = 21.5\\%$) to prevent sedimentation.\n",
    "The sample was prepared at a volume fraction $\\phi=10^{-3}$ and loaded into a 0.3 $\\times$ 3 $\\times$ 50 mm glass capillary (Vitrocom).\n",
    "The experiments were performed at $T \\simeq 21^{\\circ}\\mathrm{C}$ (solvent viscosity $\\eta = 1.78 \\, \\mathrm{mPa \\, s}$).\n",
    "\n",
    "The videos were acquired at 108 and 1 fps for the fast and slow acquisition, respectively, using a Nikon Eclipse Ti2 inverted microscope equipped with a Prime BSI Express CMOS camera (pixel size $6.5 \\, \\mathrm{µm}$).\n",
    "Each set of videos was acquired using objectives with different magnification:\n",
    "* 10$\\times$, NA 0.45\n",
    "* 20$\\times$, NA 0.45\n",
    "* 60$\\times$, NA 0.7\n",
    "\n",
    "The effective pixel size is calculated according to $\\delta_{px} = 6.5/m_o \\, \\mathrm{µm}$, where $m_o$ is the objective magnification.\n",
    "This gives in the three cases $650$, $325$, and $108 \\, \\mathrm{nm}$.\n",
    "The image sequences are composed of 10000 frames each, 256$\\times$256 pixels.\n",
    "\n",
    "### 0.C. Let's get started\n",
    "\n",
    "Let's import some essential libraries, including `fastDDM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2058787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import lmfit\n",
    "import numpy as np\n",
    "\n",
    "# set numpy print options to limit the length of the output\n",
    "np.set_printoptions(threshold=0)\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "# get rid of the 'too many open images' warning\n",
    "mpl.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# color space helper\n",
    "def color_space( \n",
    "    length: int,\n",
    "    colormap: cm.colors.LinearSegmentedColormap = cm.viridis,\n",
    "    vmin: float = 0.2, \n",
    "    vmax: float = 1.0\n",
    ") -> np.ndarray:\n",
    "    return colormap(np.linspace(vmin, vmax, length))\n",
    "\n",
    "# fastddm\n",
    "import fastddm as fd\n",
    "from fastddm.fit import fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8aeaa3",
   "metadata": {},
   "source": [
    "Here, we define the paths to the videos and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory containing the videos\n",
    "main_directory = '../DATASET/'\n",
    "\n",
    "# high frame rate videos file names (including enclosing folder)\n",
    "file_names_fast = [\n",
    "    'PS_252nm_phi_1e-3_10x_NA_0-45/fast.nd2',\n",
    "    'PS_252nm_phi_1e-3_20x_NA_0-45/fast.nd2',\n",
    "    'PS_252nm_phi_1e-3_60x_NA_0-7/fast.nd2',\n",
    "]\n",
    "\n",
    "# create full paths\n",
    "file_paths_fast = [os.path.join(main_directory, fn) for fn in file_names_fast]\n",
    "\n",
    "# low frame rate videos file names (including enclosing folder)\n",
    "file_names_slow = [\n",
    "    'PS_252nm_phi_1e-3_10x_NA_0-45/slow.nd2',\n",
    "    'PS_252nm_phi_1e-3_20x_NA_0-45/slow.nd2',\n",
    "    'PS_252nm_phi_1e-3_60x_NA_0-7/slow.nd2',\n",
    "]\n",
    "\n",
    "# create full paths\n",
    "file_paths_slow = [os.path.join(main_directory, fn) for fn in file_names_slow]\n",
    "\n",
    "# list of labels\n",
    "labels = [\n",
    "    r'10x, NA$_o$ 0.45',\n",
    "    r'20x, NA$_o$ 0.45',\n",
    "    r'60x, NA$_o$ 0.7',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeec337",
   "metadata": {},
   "source": [
    "## 1. Structure function calculation\n",
    "\n",
    "### 1.A. Load and visualize images\n",
    "\n",
    "As usual, we start by inspecting the image sequences.\n",
    "We show the first frame of the fast videos side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb35a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(ncols=len(file_paths_fast))\n",
    "axs = gs.subplots()\n",
    "\n",
    "# read the images\n",
    "images = [fd.read_images(fp, seq=[0])[0] for fp in file_paths_fast]\n",
    "images = np.array(images)\n",
    "\n",
    "for ax, img, label in zip(axs.flatten(), images, labels):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    \n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(label)\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a0c76",
   "metadata": {},
   "source": [
    "Increasing the objective magnification does what you would expect: it zooms in to see tinier things more clearly.\n",
    "\n",
    "### 1.B-C. Structure function and azimuthal average calculation\n",
    "\n",
    "The process here mirrors the one outlined in [tutorial2](../Tutorial_2-Melt/tutorial2.ipynb).\n",
    "Use the following cell to select the `core` and `mode` you wish to use for the calculation of the structure function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80959226",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNCOMMENT THE CORE YOU WISH TO USE ###\n",
    "#CORE = 'py'\n",
    "#CORE = 'cpp'\n",
    "CORE = 'cuda'\n",
    "\n",
    "### UNCOMMENT THE MODE YOU WISH TO USE ###\n",
    "#MODE = 'diff'\n",
    "MODE = 'fft'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9467b7",
   "metadata": {},
   "source": [
    "Here, we set the experimental parameters of the acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental acquisition parameters\n",
    "magnifications = [10, 20, 60]\n",
    "pixel_size = [6.5 / mag for mag in magnifications]  # microns per pixel\n",
    "\n",
    "frame_rate_fast = 108    # frames per second\n",
    "frame_rate_slow = 1      # frames per second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad2927",
   "metadata": {},
   "source": [
    "Finally, we separately compute the structure function and the azimuthal averages for the two acquisitions.\n",
    "For each pair of azimuthal averages, we compute the melt, which we will keep for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f28ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Calculating structure functions and azimuthal averages... ---')\n",
    "\n",
    "# initialize list of azimuthal averages\n",
    "aa = []\n",
    "\n",
    "for num, (fpathf, fpaths) in enumerate(zip(file_paths_fast, file_paths_slow)):\n",
    "    # analyze fast acquisition\n",
    "    # notify user on progress\n",
    "    print(f'Analyzing fast movie #{num+1} of {len(file_paths_fast)} ...')\n",
    "    \n",
    "    # read image sequence\n",
    "    img_seq = fd.read_images(fpathf)\n",
    "    \n",
    "    # compute structure function\n",
    "    lags = range(1, int(len(img_seq) / 2))              # we analyze delays only up to half the length of the video\n",
    "    dqt = fd.ddm(img_seq, lags, core=CORE, mode=MODE)\n",
    "    \n",
    "    # set pixel size and time delay\n",
    "    dqt.pixel_size = pixel_size[num]\n",
    "    dqt.set_frame_rate(frame_rate_fast)\n",
    "    \n",
    "    # compute azimuthal average\n",
    "    bins = int(len(dqt.ky) / 2)                       # number of bins\n",
    "    bin_range = (0, dqt.ky[-1])                       # bin range\n",
    "    ccm = fd.mask.central_cross_mask(dqt.shape[1:])   # mask for central cross\n",
    "    \n",
    "    aa_fast = fd.azimuthal_average(dqt, bins=bins, range=bin_range, mask=ccm)\n",
    "    \n",
    "    # delete unused variables\n",
    "    del img_seq, dqt\n",
    "    gc.collect()\n",
    "    \n",
    "    # analyze slow acquisition\n",
    "    # notify user on progress\n",
    "    print(f'Analyzing slow movie #{num+1} of {len(file_paths_slow)} ...')\n",
    "    \n",
    "    # read image sequence\n",
    "    img_seq = fd.read_images(fpaths)\n",
    "    \n",
    "    # compute structure function\n",
    "    lags = range(1, int(len(img_seq) / 2))              # we analyze delays only up to half the length of the video\n",
    "    dqt = fd.ddm(img_seq, lags, core=CORE, mode=MODE)\n",
    "    \n",
    "    # set pixel size and time delay\n",
    "    dqt.pixel_size = pixel_size[num]\n",
    "    dqt.set_frame_rate(frame_rate_slow)\n",
    "    \n",
    "    # compute azimuthal average\n",
    "    bins = int(len(dqt.ky) / 2)                       # number of bins\n",
    "    bin_range = (0, dqt.ky[-1])                       # bin range\n",
    "    ccm = fd.mask.central_cross_mask(dqt.shape[1:])   # mask for central cross\n",
    "    \n",
    "    aa_slow = fd.azimuthal_average(dqt, bins=bins, range=bin_range, mask=ccm)\n",
    "    \n",
    "    # delete unused variables\n",
    "    del img_seq, dqt\n",
    "    gc.collect()\n",
    "    \n",
    "    # melt the azimuthal averages\n",
    "    aa.append(fd.azimuthalaverage.melt(aa_fast, aa_slow))\n",
    "    \n",
    "    # delete unused variables\n",
    "    del aa_fast, aa_slow\n",
    "    gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce032c9",
   "metadata": {},
   "source": [
    "To ease plotting, we compute also resampled azimuthal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ccb0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample melt\n",
    "aa_resampled = []\n",
    "\n",
    "for a in aa:\n",
    "    new_taus = fd.lags.logspace_int(a.tau[-1] // a.tau[0], num=200) * a.tau[0]\n",
    "    aa_resampled.append(a.resample(new_taus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48497df1",
   "metadata": {},
   "source": [
    "## 2. Fit the data\n",
    "\n",
    "### 2.A. Estimate noise and amplitude\n",
    "\n",
    "To give good starting points to the fit routine, we estimate the amplitude and noise term of the structure function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate noise and amplitude terms\n",
    "Bq = []\n",
    "Aq = []\n",
    "\n",
    "for a in aa:\n",
    "    B_est, _ = fd.noise_est.estimate_camera_noise(a, mode='polyfit', num_points=5)\n",
    "    Bq.append(B_est) \n",
    "    Aq.append(2 * a.var - B_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40020d3f",
   "metadata": {},
   "source": [
    "### 2.B. Fit with simple exponential\n",
    "\n",
    "For particles undergoing Brownian motion, the intermediate scattering function is well-described by a simple exponential function:\n",
    "\n",
    "$$\n",
    "f(q, \\Delta t) = \\exp [- \\Gamma(q) \\Delta t] ,\n",
    "$$\n",
    "where $\\Gamma(q) = D q^2$ is the relaxation rate and $D$ is the particles' diffusion coefficient.\n",
    "\n",
    "We can use the `fastddm.fit_models.simple_exponential_model`, which implements the exponential function in the structure function model:\n",
    "\n",
    "$$\n",
    "d(q, \\Delta t) = A(q) [1 - \\exp(-\\Gamma(q) \\Delta t)] + B(q) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30042ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastddm.fit import fit_multik\n",
    "from fastddm.fit_models import simple_exponential_model as model\n",
    "\n",
    "# choose reference k vector\n",
    "k_ref = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4738c",
   "metadata": {},
   "source": [
    "To initiate a fitting process with a reliable starting value for the relaxation rate, we can estimate $\\tau = 1/\\Gamma$ by first estimating the intermediate scattering function and determining the delay where it has a value of $1/\\mathrm{e}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists\n",
    "fit_res = []\n",
    "model_res = []\n",
    "\n",
    "for a, B, A in zip(aa, Bq, Aq):\n",
    "    # estimate intermediate scattering function at `k_ref`\n",
    "    fqt = 1 - (a.data[k_ref] - B[k_ref]) / A[k_ref]\n",
    "    \n",
    "    # estimate Gamma\n",
    "    tau = a.tau[np.argmin(np.abs(fqt - np.exp(-1)))]\n",
    "    Gamma0 = 1 / tau\n",
    "    \n",
    "    # set model parameters hints\n",
    "    model.set_param_hint('A', value=A[k_ref])\n",
    "    model.set_param_hint('B', value=B[k_ref])\n",
    "    model.set_param_hint('Gamma', value=Gamma0)\n",
    "    \n",
    "    # fit\n",
    "    fr, mr = fit_multik(a, model, k_ref, use_err=True, return_model_results=True)\n",
    "    fit_res.append(fr)\n",
    "    model_res.append(mr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d3ca26",
   "metadata": {},
   "source": [
    "Now, we can visualize the output from the fit. We first display the comparison of the intermediate scattering function $f(\\Delta t; q)$ and the best fit, both obtained by inverting the structure function data and best fit with the resulting $A(q)$ and $B(q)$ from the fit\n",
    "\n",
    "$$\n",
    "f(q, \\Delta t) = 1 - \\frac{d(q, \\Delta t) - B(q)}{A(q)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d95541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select range of wave vector indices\n",
    "k_min = [0.07, 0.15, 0.44]\n",
    "k_max = [5, 5, 5] #[4.691, 5.159, 6.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight((len(aa) / 2) * fig.get_figheight())\n",
    "gs = fig.add_gridspec(len(aa), hspace=0)\n",
    "axs = gs.subplots(sharex=True)\n",
    "\n",
    "# plot curves\n",
    "for ax, a, ar, fr, mr, km, kM, l in zip(axs, aa, aa_resampled, fit_res, model_res, k_min, k_max, labels):\n",
    "    idx_min = np.argwhere(a.k >= km)[0,0]\n",
    "    idx_max = np.argwhere(a.k <= kM)[-1,0]\n",
    "    k_list = np.linspace(idx_min, idx_max, num=10, dtype=int)\n",
    "\n",
    "    cspace = color_space(len(k_list))\n",
    "    \n",
    "    for k_idx, c in zip(k_list, cspace):\n",
    "        # calculate intermediate scattering function\n",
    "        fqt = 1 - (ar.data[k_idx] - fr['B'][k_idx]) / fr['A'][k_idx]\n",
    "        fqt_fit = 1 - (mr[k_idx].best_fit - fr['B'][k_idx]) / fr['A'][k_idx]\n",
    "    \n",
    "        # plot\n",
    "        ax.plot(ar.tau, fqt, '.', color=c)\n",
    "        ax.plot(a.tau, fqt_fit, '-', color=c)\n",
    "        \n",
    "        # misc\n",
    "        ax.set_ylabel(r'$f(\\Delta t; q)$')\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        # label\n",
    "        at = AnchoredText(l, prop=dict(size=10), frameon=True, loc='upper right')\n",
    "        ax.add_artist(at)\n",
    "        # custom legend\n",
    "        custom_lines = [\n",
    "            Line2D([0], [0], marker='.', linestyle='none', color='black', label='data'),\n",
    "            Line2D([0], [0], linestyle='-', color='black', label='fit'),\n",
    "        ]\n",
    "        ax.legend(handles=custom_lines, labelspacing=0.4, loc='lower left')\n",
    "        \n",
    "axs[-1].set_xscale('log')\n",
    "axs[-1].set_xlabel(r'$\\Delta t$ (s)')\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ae6e59",
   "metadata": {},
   "source": [
    "### 2.C. Effect of objective magnification on the output\n",
    "\n",
    "Finally, we show the fit parameters, $\\Gamma$, $A$, and $B$.\n",
    "We also display the lower limit $q_{\\text{min}}$ defined in [tutorial1](../Tutorial_1-Particle_sizing/tutorial1.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optical parameters\n",
    "L = np.array([256 * ps for ps in pixel_size])\n",
    "NAo = np.array([0.45, 0.45, 0.7])\n",
    "lambda0 = 0.53\n",
    "\n",
    "# limits\n",
    "q_min = 2 * np.pi / L\n",
    "q_max = 2 * np.pi * NAo / lambda0\n",
    "gamma_0 = 1 / aa[0].tau[0]    # also, gamma_0 = frame_rate\n",
    "gamma_T = 1 / aa[0].tau[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(1.5 * fig.get_figheight())\n",
    "gs = fig.add_gridspec(2, hspace=0)\n",
    "axs = gs.subplots(sharex=True)\n",
    "\n",
    "# plot\n",
    "for n, (fr, label) in enumerate(zip(fit_res, labels)):\n",
    "    # filter only nan and non-successful fits\n",
    "    tmp_df = fr[fr['success']].dropna()\n",
    "    \n",
    "    # display the full data (with transparency)\n",
    "    axs[0].errorbar(\n",
    "        tmp_df['k'],\n",
    "        tmp_df['Gamma'],\n",
    "        yerr=tmp_df['Gamma_stderr'],\n",
    "        fmt=f'C{n}o',\n",
    "        markerfacecolor='none',\n",
    "        label=label\n",
    "    )\n",
    "    axs[1].errorbar(\n",
    "        tmp_df['k'],\n",
    "        tmp_df['A'],\n",
    "        yerr=tmp_df['A_stderr'],\n",
    "        fmt=f'C{n}o',\n",
    "        markerfacecolor='none',\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        tmp_df['k'],\n",
    "        np.full_like(tmp_df['B'], fill_value=tmp_df['B'].mean()),\n",
    "        f'C{n}--',\n",
    "    )\n",
    "\n",
    "# settings\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_ylabel(r'$\\Gamma$ (s$^{-1}$)')\n",
    "axs[0].legend(loc='upper left')\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_xlabel(r'$q$ ($\\mu$m$^{-1}$)')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_ylabel(r'$A$, $B$')\n",
    "custom_lines = [\n",
    "    Line2D([0], [0], marker='o', linestyle='none', markerfacecolor='none', color='black', label=r'$A$'),\n",
    "    Line2D([0], [0], linestyle='--', color='black', label=r'$B$'),\n",
    "]\n",
    "axs[1].legend(handles=custom_lines, labelspacing=0.4, loc='upper right')\n",
    "\n",
    "# plot Gamma limits\n",
    "axs[0].axhline(gamma_T, color='gray', linestyle='--', alpha=0.5)\n",
    "axs[0].axhline(gamma_0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# plot q limits\n",
    "for n, qm in enumerate(q_min):\n",
    "    axs[0].axvline(x=qm, color=f'C{n}', linestyle='-.', alpha=0.5)\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8dace",
   "metadata": {},
   "source": [
    "The vertical dash-dotted lines in the upper panel are the $q_{\\text{min}} = 2 \\pi / L$ limits for the three objectives.\n",
    "The effect of the objective magnification (at equal image size in pixels) is to shift the lower boundary of the $q$ range proportionally to the magnification itself.\n",
    "\n",
    "We can again filter the fit results as we saw in the first tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2839ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter fit results\n",
    "fit_res_filtered = []\n",
    "\n",
    "for fr, qm, qM in zip(fit_res, q_min, q_max):\n",
    "    # remove non-succesful fits and nans\n",
    "    tmp_df = fr[fr['success']].dropna()\n",
    "    \n",
    "    # filter q range\n",
    "    tmp_df = tmp_df[(tmp_df['k'] >= qm) & (tmp_df['k'] <= qM)]\n",
    "    \n",
    "    # filter Gamma range\n",
    "    tmp_df = tmp_df[(tmp_df['Gamma'] >= gamma_T) & (tmp_df['Gamma'] <= gamma_0)]\n",
    "    \n",
    "    # append to list\n",
    "    fit_res_filtered.append(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ecfe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(1.5 * fig.get_figheight())\n",
    "gs = fig.add_gridspec(2, hspace=0)\n",
    "axs = gs.subplots(sharex=True)\n",
    "\n",
    "# plot\n",
    "for n, (fr, label) in enumerate(zip(fit_res_filtered, labels)):\n",
    "    \n",
    "    # display the full data (with transparency)\n",
    "    axs[0].errorbar(\n",
    "        fr['k'],\n",
    "        fr['Gamma'],\n",
    "        yerr=fr['Gamma_stderr'],\n",
    "        fmt=f'C{n}o',\n",
    "        markerfacecolor='none',\n",
    "        label=label\n",
    "    )\n",
    "    axs[1].errorbar(\n",
    "        fr['k'],\n",
    "        fr['A'],\n",
    "        yerr=fr['A_stderr'],\n",
    "        fmt=f'C{n}o',\n",
    "        markerfacecolor='none',\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        fr['k'],\n",
    "        np.full_like(fr['B'], fill_value=fr['B'].mean()),\n",
    "        f'C{n}--',\n",
    "    )\n",
    "\n",
    "# settings\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_ylabel(r'$\\Gamma$ (s$^{-1}$)')\n",
    "axs[0].legend()\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_xlabel(r'$q$ ($\\mu$m$^{-1}$)')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_ylabel(r'$A$, $B$')\n",
    "custom_lines = [\n",
    "    Line2D([0], [0], marker='o', linestyle='none', markerfacecolor='none', color='black', label=r'$A$'),\n",
    "    Line2D([0], [0], linestyle='--', color='black', label=r'$B$'),\n",
    "]\n",
    "axs[1].legend(handles=custom_lines, labelspacing=0.4, loc='upper right')\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40048774",
   "metadata": {},
   "source": [
    "Notice that the amplitude seems to scale with the square of the objective magnification.\n",
    "To check this, we analyze measurements performed on the same sample with the first two objectives (10$\\times$ and 20$\\times$) and using different lamp intensities, measured as the average signal registered by the camera sensor (10k, 25k, and 50k).\n",
    "\n",
    "The next code cells repeat what we have seen so far, so we will not comment further on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c599555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high frame rate videos file names (including enclosing folder)\n",
    "file_names_fast2 = [\n",
    "    'PS_252nm_phi_1e-3_10x_NA_0-45_10k/fast.nd2',\n",
    "    'PS_252nm_phi_1e-3_10x_NA_0-45_25k/fast.nd2',\n",
    "    'PS_252nm_phi_1e-3_10x_NA_0-45_50k/fast.nd2',\n",
    "    'PS_252nm_phi_1e-3_20x_NA_0-45_10k/fast.nd2',\n",
    "    'PS_252nm_phi_1e-3_20x_NA_0-45_25k/fast.nd2',\n",
    "    'PS_252nm_phi_1e-3_20x_NA_0-45_50k/fast.nd2',\n",
    "]\n",
    "\n",
    "# create full paths\n",
    "file_paths_fast2 = [os.path.join(main_directory, fn) for fn in file_names_fast2]\n",
    "\n",
    "# low frame rate videos file names (including enclosing folder)\n",
    "file_names_slow2 = [\n",
    "    'PS_252nm_phi_1e-3_10x_NA_0-45_10k/slow.nd2',\n",
    "    'PS_252nm_phi_1e-3_10x_NA_0-45_25k/slow.nd2',\n",
    "    'PS_252nm_phi_1e-3_10x_NA_0-45_50k/slow.nd2',\n",
    "    'PS_252nm_phi_1e-3_20x_NA_0-45_10k/slow.nd2',\n",
    "    'PS_252nm_phi_1e-3_20x_NA_0-45_25k/slow.nd2',\n",
    "    'PS_252nm_phi_1e-3_20x_NA_0-45_50k/slow.nd2',\n",
    "]\n",
    "\n",
    "# create full paths\n",
    "file_paths_slow2 = [os.path.join(main_directory, fn) for fn in file_names_slow2]\n",
    "\n",
    "# list of labels\n",
    "labels2 = [\n",
    "    r'10x, 10k',\n",
    "    r'10x, 25k',\n",
    "    r'10x, 50k',\n",
    "    r'20x, 10k',\n",
    "    r'20x, 25k',\n",
    "    r'20x, 50k',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(ncols=3, nrows=2)\n",
    "axs = gs.subplots()\n",
    "\n",
    "# read the images\n",
    "images = [fd.read_images(fp, seq=[0])[0] for fp in file_paths_fast2]\n",
    "images = np.array(images)\n",
    "\n",
    "for ax, img, label in zip(axs.flatten(), images, labels2):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    \n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(label)\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a8f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Calculating structure functions and azimuthal averages... ---')\n",
    "\n",
    "# initialize list of azimuthal averages\n",
    "aa2 = []\n",
    "\n",
    "for num, (fpathf, fpaths) in enumerate(zip(file_paths_fast2, file_paths_slow2)):\n",
    "    # analyze fast acquisition\n",
    "    # notify user on progress\n",
    "    print(f'Analyzing fast movie #{num+1} of {len(file_paths_fast2)} ...')\n",
    "    \n",
    "    # read image sequence\n",
    "    img_seq = fd.read_images(fpathf)\n",
    "    \n",
    "    # compute structure function\n",
    "    lags = range(1, int(len(img_seq) / 2))              # we analyze delays only up to half the length of the video\n",
    "    dqt = fd.ddm(img_seq, lags, core=CORE, mode=MODE)\n",
    "    \n",
    "    # set pixel size and time delay\n",
    "    dqt.pixel_size = pixel_size[num // 3]\n",
    "    dqt.set_frame_rate(frame_rate_fast)\n",
    "    \n",
    "    # compute azimuthal average\n",
    "    bins = int(len(dqt.ky) / 2)                       # number of bins\n",
    "    bin_range = (0, dqt.ky[-1])                       # bin range\n",
    "    ccm = fd.mask.central_cross_mask(dqt.shape[1:])   # mask for central cross\n",
    "    \n",
    "    aa_fast = fd.azimuthal_average(dqt, bins=bins, range=bin_range, mask=ccm)\n",
    "    \n",
    "    # delete unused variables\n",
    "    del img_seq, dqt\n",
    "    gc.collect()\n",
    "    \n",
    "    # analyze slow acquisition\n",
    "    # notify user on progress\n",
    "    print(f'Analyzing slow movie #{num+1} of {len(file_paths_slow2)} ...')\n",
    "    \n",
    "    # read image sequence\n",
    "    img_seq = fd.read_images(fpaths)\n",
    "    \n",
    "    # compute structure function\n",
    "    lags = range(1, int(len(img_seq) / 2))              # we analyze delays only up to half the length of the video\n",
    "    dqt = fd.ddm(img_seq, lags, core=CORE, mode=MODE)\n",
    "    \n",
    "    # set pixel size and time delay\n",
    "    dqt.pixel_size = pixel_size[num // 3]\n",
    "    dqt.set_frame_rate(frame_rate_slow)\n",
    "    \n",
    "    # compute azimuthal average\n",
    "    bins = int(len(dqt.ky) / 2)                       # number of bins\n",
    "    bin_range = (0, dqt.ky[-1])                       # bin range\n",
    "    ccm = fd.mask.central_cross_mask(dqt.shape[1:])   # mask for central cross\n",
    "    \n",
    "    aa_slow = fd.azimuthal_average(dqt, bins=bins, range=bin_range, mask=ccm)\n",
    "    \n",
    "    # delete unused variables\n",
    "    del img_seq, dqt\n",
    "    gc.collect()\n",
    "    \n",
    "    # melt the azimuthal averages\n",
    "    aa2.append(fd.azimuthalaverage.melt(aa_fast, aa_slow))\n",
    "    \n",
    "    # delete unused variables\n",
    "    del aa_fast, aa_slow\n",
    "    gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample melt\n",
    "aa_resampled2 = []\n",
    "\n",
    "for a in aa2:\n",
    "    new_taus = fd.lags.logspace_int(a.tau[-1] // a.tau[0], num=200) * a.tau[0]\n",
    "    aa_resampled2.append(a.resample(new_taus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a85fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate noise and amplitude terms\n",
    "Bq2 = []\n",
    "Aq2 = []\n",
    "\n",
    "for a in aa2:\n",
    "    B_est, _ = fd.noise_est.estimate_camera_noise(a, mode='polyfit', num_points=5)\n",
    "    Bq2.append(B_est) \n",
    "    Aq2.append(2 * a.var - B_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8960e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit data\n",
    "# initialize lists\n",
    "fit_res2 = []\n",
    "model_res2 = []\n",
    "\n",
    "for a, B, A in zip(aa2, Bq2, Aq2):\n",
    "    # estimate intermediate scattering function at `k_ref`\n",
    "    fqt = 1 - (a.data[k_ref] - B[k_ref]) / A[k_ref]\n",
    "    \n",
    "    # estimate Gamma\n",
    "    tau = a.tau[np.argmin(np.abs(fqt - np.exp(-1)))]\n",
    "    Gamma0 = 1 / tau\n",
    "    \n",
    "    # set model parameters hints\n",
    "    model.set_param_hint('A', value=A[k_ref])\n",
    "    model.set_param_hint('B', value=B[k_ref])\n",
    "    model.set_param_hint('Gamma', value=Gamma0)\n",
    "    \n",
    "    # fit\n",
    "    fr, mr = fit_multik(a, model, k_ref, use_err=True, return_model_results=True)\n",
    "    fit_res2.append(fr)\n",
    "    model_res2.append(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01dcf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(1.5 * fig.get_figheight())\n",
    "gs = fig.add_gridspec(2, hspace=0)\n",
    "axs = gs.subplots(sharex=True)\n",
    "\n",
    "# plot\n",
    "for n, (fr, label) in enumerate(zip(fit_res2, labels2)):\n",
    "    # filter only nan and non-successful fits\n",
    "    tmp_df = fr[fr['success']].dropna()\n",
    "    \n",
    "    # display the full data (with transparency)\n",
    "    axs[0].errorbar(\n",
    "        tmp_df['k'],\n",
    "        tmp_df['Gamma'],\n",
    "        yerr=tmp_df['Gamma_stderr'],\n",
    "        fmt=f'C{n}o',\n",
    "        markerfacecolor='none',\n",
    "        label=label\n",
    "    )\n",
    "    axs[1].errorbar(\n",
    "        tmp_df['k'],\n",
    "        tmp_df['A'],\n",
    "        yerr=tmp_df['A_stderr'],\n",
    "        fmt=f'C{n}o',\n",
    "        markerfacecolor='none',\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        tmp_df['k'],\n",
    "        np.full_like(tmp_df['B'], fill_value=tmp_df['B'].mean()),\n",
    "        f'C{n}--',\n",
    "    )\n",
    "\n",
    "# settings\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_ylabel(r'$\\Gamma$ (s$^{-1}$)')\n",
    "axs[0].legend(loc='upper left')\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_xlabel(r'$q$ ($\\mu$m$^{-1}$)')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_ylabel(r'$A$, $B$')\n",
    "custom_lines = [\n",
    "    Line2D([0], [0], marker='o', linestyle='none', markerfacecolor='none', color='black', label=r'$A$'),\n",
    "    Line2D([0], [0], linestyle='--', color='black', label=r'$B$'),\n",
    "]\n",
    "axs[1].legend(handles=custom_lines, labelspacing=0.4, loc='upper right')\n",
    "\n",
    "# plot Gamma limits\n",
    "axs[0].axhline(gamma_T, color='gray', linestyle='--', alpha=0.5)\n",
    "axs[0].axhline(gamma_0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# plot q limits\n",
    "for n, qm in enumerate(q_min[:2]):\n",
    "    axs[0].axvline(x=qm, color=f'C{n*3}', linestyle='-.', alpha=0.5)\n",
    "\n",
    "fig.tight_layout();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
